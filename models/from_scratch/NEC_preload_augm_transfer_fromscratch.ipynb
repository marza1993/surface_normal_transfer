{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"normal_estimation_classification_preload_augm_transfer_fromscratch.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"cXl2LIsHBk9A","colab_type":"text"},"source":["#Installazione pacchetti necessari"]},{"cell_type":"markdown","metadata":{"id":"JVK2YhY_fQXT","colab_type":"text"},"source":["# Connessione a directory Drive"]},{"cell_type":"code","metadata":{"id":"i6Nt5L3oermW","colab_type":"code","outputId":"e1c51df5-b2d7-4a9b-84ad-5c65808fdf9f","executionInfo":{"status":"ok","timestamp":1590217608699,"user_tz":-120,"elapsed":13635,"user":{"displayName":"Andrea Scalvini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPXeWNqyQHU7lqzAh6lutN43ztPT6kRjC-mBXV=s64","userId":"07368200968117513143"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JKAzI_xNfUWB","colab_type":"text"},"source":["# Loading Dataset pre processing compresso"]},{"cell_type":"code","metadata":{"id":"THTHHUIVfPUP","colab_type":"code","colab":{}},"source":["import numpy as np\n","PATH_BASE = '/content/drive/My Drive/Appunti delle lezioni/2Anno2Semestre/Digital Image Processing/npy_files/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z6Yh3OxiTEI_","colab_type":"code","colab":{}},"source":["dataset_splitted_augm = np.load(PATH_BASE + \"dataset_splitted_nneigh_pad_augm.npz\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mVp18GHqm59d","colab_type":"text"},"source":["# Caricamento strutture già splittate"]},{"cell_type":"code","metadata":{"id":"C_YXc_wRm9M4","colab_type":"code","colab":{}},"source":["x_train = dataset_splitted_augm['img_train']\n","x_val = dataset_splitted_augm['img_val']\n","x_test = dataset_splitted_augm['img_test']\n","mask_train = dataset_splitted_augm['mask_train']\n","mask_val = dataset_splitted_augm['mask_val']\n","mask_test = dataset_splitted_augm['mask_test']\n","map_indexes = dataset_splitted_augm['map_indexes']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dkifSxZGPhN_","colab_type":"text"},"source":["## Passaggio a 41 channel su validation e train set"]},{"cell_type":"markdown","metadata":{"id":"urThIMc80uxG","colab_type":"text"},"source":["Si passa da WxH a WxHxC dove C rappresenta i singoli cluster"]},{"cell_type":"code","metadata":{"id":"PEYCVGhoUifh","colab_type":"code","colab":{}},"source":["recompute = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Oz6DNaI06gX","colab_type":"code","colab":{}},"source":["def process_channels(reshaped_labels, n_labels):\n","  reshaped_labels_processed = np.zeros((reshaped_labels.shape[0], reshaped_labels.shape[1], reshaped_labels.shape[2], n_labels), dtype=\"uint8\")\n","  for n in range(0, reshaped_labels_processed.shape[0]):\n","    for i in range(0, reshaped_labels_processed.shape[1]):\n","      for j in range(0, reshaped_labels_processed.shape[2]):\n","        reshaped_labels_processed[n][i][j][reshaped_labels[n][i][j]] = 1\n","  return reshaped_labels_processed"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hUYyjbUcRNdE","colab_type":"code","colab":{}},"source":["if recompute:\n","  y_train = process_channels(mask_train, 40)\n","  y_val = process_channels(mask_val, 40)\n","  np.savez_compressed(PATH_BASE + \"normals_centroid_labels_pad_augm_41channels.npz\", \n","                      y_train = y_train,\n","                      y_val = y_val)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yxLK-vw5_P__","colab_type":"code","colab":{}},"source":["reshaped_labels_processed_load = np.load(PATH_BASE + \"normals_centroid_labels_pad_augm_41channels.npz\")\n","y_train = reshaped_labels_processed_load[\"y_train\"]\n","y_val = reshaped_labels_processed_load[\"y_val\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jm2b7YTOuiWA","colab_type":"code","outputId":"a5bd1d87-4733-440f-f91b-4f3cc3265cae","executionInfo":{"status":"ok","timestamp":1590217643163,"user_tz":-120,"elapsed":48035,"user":{"displayName":"Andrea Scalvini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPXeWNqyQHU7lqzAh6lutN43ztPT6kRjC-mBXV=s64","userId":"07368200968117513143"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["y_train.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(810, 320, 320, 41)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"0vrPAlXTgViQ","colab_type":"text"},"source":["# Modellizzazione"]},{"cell_type":"markdown","metadata":{"id":"AIfdesYESNlx","colab_type":"text"},"source":["## Costruzione modello"]},{"cell_type":"code","metadata":{"id":"CcRpTOmTjfwQ","colab_type":"code","outputId":"1de8dd2a-b750-4ba5-a020-61be49992802","executionInfo":{"status":"ok","timestamp":1590217645119,"user_tz":-120,"elapsed":49983,"user":{"displayName":"Andrea Scalvini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPXeWNqyQHU7lqzAh6lutN43ztPT6kRjC-mBXV=s64","userId":"07368200968117513143"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import cv2\n","import tensorflow as tf\n","import keras\n","#import tensorflow.keras\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"31NF5OukjlNv","colab_type":"code","colab":{}},"source":["# helper function for data visualization\n","def visualize(**images):\n","    \"\"\"PLot images in one row.\"\"\"\n","    n = len(images)\n","    plt.figure(figsize=(16, 5))\n","    for i, (name, image) in enumerate(images.items()):\n","        plt.subplot(1, n, i + 1)\n","        plt.xticks([])\n","        plt.yticks([])\n","        plt.title(' '.join(name.split('_')).title())\n","        plt.imshow(image)\n","    plt.show()\n","    \n","# helper function for data visualization    \n","def denormalize(x):\n","    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n","    x_max = np.percentile(x, 98)\n","    x_min = np.percentile(x, 2)    \n","    x = (x - x_min) / (x_max - x_min)\n","    x = x.clip(0, 1)\n","    return x "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GOwCIFN6p0Dp","colab_type":"code","colab":{}},"source":["# classes for data loading and preprocessing\n","class Dataset:\n","    \"\"\"Normal surface dataset. Read images, apply augmentation and preprocessing transformations.\n","    \n","    Args:\n","        x (nparray): images\n","        y (nparray): label\n","        augmentation (albumentations.Compose): data transfromation pipeline \n","            (e.g. flip, scale, etc.)\n","        preprocessing (albumentations.Compose): data preprocessing \n","            (e.g. noralization, shape manipulation, etc.)\n","    \n","    \"\"\"\n","    \n","    def __init__(\n","            self, \n","            x, \n","            y, \n","            mapping,\n","    ):\n","        self.x = x\n","        self.y = y\n","        self.mapping = mapping\n","    \n","    def __getitem__(self, i):\n","        image = self.x[i,]\n","        label = self.y[self.mapping[i],]\n","        return image, label\n","        \n","    def __len__(self):\n","        return self.x.shape[0]\n","      \n","class Dataloder(tf.keras.utils.Sequence):\n","    \"\"\"Load data from dataset and form batches\n","    \n","    Args:\n","        dataset: instance of Dataset class for image loading and preprocessing.\n","        batch_size: Integet number of images in batch.\n","        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n","    \"\"\"\n","    \n","    def __init__(self, dataset, batch_size=1, shuffle=False):\n","        self.dataset = dataset\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.indexes = np.arange(len(dataset))\n","\n","        self.on_epoch_end()\n","\n","    def __getitem__(self, i):\n","        \n","        # collect batch data\n","        start = i * self.batch_size\n","        stop = (i + 1) * self.batch_size\n","        #X = []\n","        #Y = []\n","        data = []\n","        for j in range(start, stop):\n","            data.append(self.dataset[j])\n","            #x, y = self.dataset[j]\n","            #X.append(x)\n","            #Y.append(y)\n","        \n","        # transpose list of lists\n","        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n","        \n","        #batch = [np.stack(samples, axis=0) for samples in zip(self.dataset[(start, stop)])]\n","        #batch = self.dataset[(start,stop)]\n","        #return np.asarray(X),np.asarray(Y)\n","        return batch\n","    \n","    def __len__(self):\n","        \"\"\"Denotes the number of batches per epoch\"\"\"\n","        return len(self.indexes) // self.batch_size\n","    \n","    def on_epoch_end(self):\n","        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n","        if self.shuffle:\n","            self.indexes = np.random.permutation(self.indexes)  \n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pJeP8VH5kFzt","colab_type":"text"},"source":["### Costruzione modello UNet"]},{"cell_type":"code","metadata":{"id":"lTp-3YxPoKx2","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","from keras.models import Model, load_model\n","from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, UpSampling2D\n","from keras.layers.core import Lambda, RepeatVector, Reshape, SpatialDropout2D\n","from keras.layers.convolutional import Conv2D, Conv2DTranspose\n","from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n","from keras.layers.merge import concatenate, add\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from keras.optimizers import Adam\n","\n","from keras import backend as K"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nmS5WCDiwRZP","colab_type":"text"},"source":["### Costruzione ZF UNET 224"]},{"cell_type":"code","metadata":{"id":"Ll5KLJGutTa1","colab_type":"code","colab":{}},"source":["def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n","\n","\n","def jacard_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n","\n","\n","def jacard_coef_loss(y_true, y_pred):\n","    return -jacard_coef(y_true, y_pred)\n","\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return -dice_coef(y_true, y_pred)\n","\n","\n","def double_conv_layer(x, size, dropout=0.0, batch_norm=True):\n","    axis = 3\n","    conv = Conv2D(size, (3, 3), padding='same')(x)\n","    if batch_norm is True:\n","        conv = BatchNormalization(axis=axis)(conv)\n","    conv = Activation('relu')(conv)\n","    conv = Conv2D(size, (3, 3), padding='same')(conv)\n","    if batch_norm is True:\n","        conv = BatchNormalization(axis=axis)(conv)\n","    conv = Activation('relu')(conv)\n","    if dropout > 0:\n","        conv = SpatialDropout2D(dropout)(conv)\n","    return conv\n","\n","\n","def ZF_UNET_224(dims, output_mask_channels, weights_file, dropout_val=0.2):\n","    inputs = Input((dims[0], dims[1], dims[2]))\n","    axis = 3\n","    filters = 32\n","\n","    conv_224 = double_conv_layer(inputs, filters)\n","    pool_112 = MaxPooling2D(pool_size=(2, 2))(conv_224)\n","\n","    conv_112 = double_conv_layer(pool_112, 2*filters)\n","    pool_56 = MaxPooling2D(pool_size=(2, 2))(conv_112)\n","\n","    conv_56 = double_conv_layer(pool_56, 4*filters)\n","    pool_28 = MaxPooling2D(pool_size=(2, 2))(conv_56)\n","\n","    conv_28 = double_conv_layer(pool_28, 8*filters)\n","    pool_14 = MaxPooling2D(pool_size=(2, 2))(conv_28)\n","\n","    conv_14 = double_conv_layer(pool_14, 16*filters)\n","    pool_7 = MaxPooling2D(pool_size=(2, 2))(conv_14)\n","\n","    conv_7 = double_conv_layer(pool_7, 32*filters)\n","\n","    up_14 = concatenate([UpSampling2D(size=(2, 2))(conv_7), conv_14], axis=axis)\n","    up_conv_14 = double_conv_layer(up_14, 16*filters)\n","\n","    up_28 = concatenate([UpSampling2D(size=(2, 2))(up_conv_14), conv_28], axis=axis)\n","    up_conv_28 = double_conv_layer(up_28, 8*filters)\n","\n","    up_56 = concatenate([UpSampling2D(size=(2, 2))(up_conv_28), conv_56], axis=axis)\n","    up_conv_56 = double_conv_layer(up_56, 4*filters)\n","\n","    up_112 = concatenate([UpSampling2D(size=(2, 2))(up_conv_56), conv_112], axis=axis)\n","    up_conv_112 = double_conv_layer(up_112, 2*filters)\n","\n","    up_224 = concatenate([UpSampling2D(size=(2, 2))(up_conv_112), conv_224], axis=axis)\n","    up_conv_224 = double_conv_layer(up_224, filters, dropout_val)\n","\n","    conv_final = Conv2D(output_mask_channels, (1, 1), name = \"final\")(up_conv_224)\n","    conv_final = Activation('softmax')(conv_final)\n","\n","    model = Model(inputs, conv_final, name=\"ZF_UNET_224\")\n","\n","        #weights_path = get_file(\n","        #    'zf_unet_224_weights_tf_dim_ordering_tf_generator.h5',\n","        #    ZF_UNET_224_WEIGHT_PATH,\n","        #    cache_subdir='models',\n","        #    file_hash='203146f209baf34ac0d793e1691f1ab7')\n","    model.load_weights(weights_file, by_name = True)\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tn2as37PsYsO","colab_type":"code","outputId":"b4eea3cf-789c-41ca-bacc-9b76e84b3679","executionInfo":{"status":"ok","timestamp":1590217659411,"user_tz":-120,"elapsed":64233,"user":{"displayName":"Andrea Scalvini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPXeWNqyQHU7lqzAh6lutN43ztPT6kRjC-mBXV=s64","userId":"07368200968117513143"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["!wget https://github.com/ZFTurbo/ZF_UNET_224_Pretrained_Model/releases/download/v1.0/zf_unet_224.h5"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-05-23 07:07:27--  https://github.com/ZFTurbo/ZF_UNET_224_Pretrained_Model/releases/download/v1.0/zf_unet_224.h5\n","Resolving github.com (github.com)... 140.82.113.3\n","Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/90289853/f2ef3528-2bb4-11e8-84bd-664c6a7e0ef6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200523%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200523T070727Z&X-Amz-Expires=300&X-Amz-Signature=be4d0e803ec977548073dfdd8413008e5cc28193a46822aeb66e76294d61fd13&X-Amz-SignedHeaders=host&actor_id=0&repo_id=90289853&response-content-disposition=attachment%3B%20filename%3Dzf_unet_224.h5&response-content-type=application%2Foctet-stream [following]\n","--2020-05-23 07:07:27--  https://github-production-release-asset-2e65be.s3.amazonaws.com/90289853/f2ef3528-2bb4-11e8-84bd-664c6a7e0ef6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200523%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200523T070727Z&X-Amz-Expires=300&X-Amz-Signature=be4d0e803ec977548073dfdd8413008e5cc28193a46822aeb66e76294d61fd13&X-Amz-SignedHeaders=host&actor_id=0&repo_id=90289853&response-content-disposition=attachment%3B%20filename%3Dzf_unet_224.h5&response-content-type=application%2Foctet-stream\n","Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.217.19.4\n","Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.217.19.4|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 126056656 (120M) [application/octet-stream]\n","Saving to: ‘zf_unet_224.h5’\n","\n","zf_unet_224.h5      100%[===================>] 120.22M  15.8MB/s    in 8.8s    \n","\n","2020-05-23 07:07:37 (13.6 MB/s) - ‘zf_unet_224.h5’ saved [126056656/126056656]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j9MdAFcxudho","colab_type":"code","colab":{}},"source":["# Image dimensions\n","DIMS = (320,320,3)\n","# Number of image channels (for example 3 in case of RGB, or 1 for grayscale images)\n","INPUT_CHANNELS = 3\n","# Number of output masks (1 in case you predict only one type of objects)\n","OUTPUT_MASK_CHANNELS = 41\n","# Pretrained weights\n","#ZF_UNET_224_WEIGHT_PATH = 'https://github.com/ZFTurbo/ZF_UNET_224_Pretrained_Model/releases/download/v1.0/zf_unet_224.h5'\n","ZF_UNET_224_WEIGHT_PATH = \"zf_unet_224.h5\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_QWZnzzHwD45","colab_type":"code","colab":{}},"source":["model = ZF_UNET_224(DIMS, OUTPUT_MASK_CHANNELS, ZF_UNET_224_WEIGHT_PATH)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6jsb76yDy8Jn","colab_type":"code","colab":{}},"source":["for layer in model.layers[:-2]:\n","  layer.trainable = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kyByMhomsWw1","colab_type":"code","colab":{}},"source":["from keras import backend as K\n","def f1(y_true, y_pred):\n","    def recall(y_true, y_pred):\n","        \"\"\"Recall metric.\n","\n","        Only computes a batch-wise average of recall.\n","\n","        Computes the recall, a metric for multi-label classification of\n","        how many relevant items are selected.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","    def precision(y_true, y_pred):\n","        \"\"\"Precision metric.\n","\n","        Only computes a batch-wise average of precision.\n","\n","        Computes the precision, a metric for multi-label classification of\n","        how many selected items are relevant.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gyH57h0w-eOC","colab_type":"text"},"source":["###Calcolo dei pesi"]},{"cell_type":"code","metadata":{"id":"EmphqaA1iHhT","colab_type":"code","colab":{}},"source":["from sklearn.utils import class_weight\n","def computeLabelWeights(reshaped_labels):\n","  labelList = []\n","  for n in range(0, reshaped_labels.shape[0]):\n","    for i in range(0, reshaped_labels.shape[1]):\n","      for j in range(0, reshaped_labels.shape[2]):\n","        labelList.append(reshaped_labels[n][i][j])\n","\n","  return class_weight.compute_class_weight('balanced',np.unique(labelList),labelList).tolist()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hHZ_l87eiS4d","colab_type":"code","colab":{}},"source":["if recompute:\n","  dataset_preprocess_nneigh_pad_augm = np.load(PATH_BASE + \"dataset_pre_processing.npz\")\n","  reshaped_labels = dataset_preprocess_nneigh_pad_augm['reshaped_labels']\n","  class_weight = computeLabelWeights(reshaped_labels)\n","  np.save(PATH_BASE + \"label_weights_nneigh_pad.npy\", class_weight)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1J9L9pTBtKut","colab":{}},"source":["class_weights = np.load(PATH_BASE + \"label_weights_nneigh_pad.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pgODcHe1sBXj","colab_type":"text"},"source":["### Definizione funzione di Loss"]},{"cell_type":"code","metadata":{"id":"ecsWBfnLe96X","colab_type":"code","colab":{}},"source":["def weighted_categorical_crossentropy(weights):\n","    \"\"\"\n","    A weighted version of keras.objectives.categorical_crossentropy\n","    \n","    Variables:\n","        weights: numpy array of shape (C,) where C is the number of classes\n","    \n","    Usage:\n","        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n","        loss = weighted_categorical_crossentropy(weights)\n","        model.compile(loss=loss,optimizer='adam')\n","    \"\"\"\n","    \n","    weights = K.variable(weights)\n","        \n","    def loss(y_true, y_pred):\n","        # scale predictions so that the class probas of each sample sum to 1\n","        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n","        # clip to prevent NaN's and Inf's\n","        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n","        # calc\n","        loss = y_true * K.log(y_pred) * weights\n","        loss = -K.sum(loss, -1)\n","        return loss\n","    \n","    return loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ymsGqHE8oNPJ","colab_type":"code","outputId":"0137134b-c267-4bed-df59-9f2ce300a345","executionInfo":{"status":"ok","timestamp":1590222778682,"user_tz":-120,"elapsed":1299,"user":{"displayName":"Andrea Scalvini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPXeWNqyQHU7lqzAh6lutN43ztPT6kRjC-mBXV=s64","userId":"07368200968117513143"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.compile(optimizer=Adam(), loss=weighted_categorical_crossentropy(class_weights), metrics=[dice_coef, f1])\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"ZF_UNET_224\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 320, 320, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 320, 320, 32) 896         input_3[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 320, 320, 32) 128         conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 320, 320, 32) 0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 320, 320, 32) 9248        activation_47[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 320, 320, 32) 128         conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 320, 320, 32) 0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_11 (MaxPooling2D) (None, 160, 160, 32) 0           activation_48[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 160, 160, 64) 18496       max_pooling2d_11[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 160, 160, 64) 256         conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 160, 160, 64) 0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 160, 160, 64) 36928       activation_49[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 160, 160, 64) 256         conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 160, 160, 64) 0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_12 (MaxPooling2D) (None, 80, 80, 64)   0           activation_50[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 80, 80, 128)  73856       max_pooling2d_12[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 80, 80, 128)  512         conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","activation_51 (Activation)      (None, 80, 80, 128)  0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 80, 80, 128)  147584      activation_51[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 80, 80, 128)  512         conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","activation_52 (Activation)      (None, 80, 80, 128)  0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_13 (MaxPooling2D) (None, 40, 40, 128)  0           activation_52[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 40, 40, 256)  295168      max_pooling2d_13[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 40, 40, 256)  1024        conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","activation_53 (Activation)      (None, 40, 40, 256)  0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 40, 40, 256)  590080      activation_53[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_52 (BatchNo (None, 40, 40, 256)  1024        conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","activation_54 (Activation)      (None, 40, 40, 256)  0           batch_normalization_52[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_14 (MaxPooling2D) (None, 20, 20, 256)  0           activation_54[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_53 (Conv2D)              (None, 20, 20, 512)  1180160     max_pooling2d_14[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_53 (BatchNo (None, 20, 20, 512)  2048        conv2d_53[0][0]                  \n","__________________________________________________________________________________________________\n","activation_55 (Activation)      (None, 20, 20, 512)  0           batch_normalization_53[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_54 (Conv2D)              (None, 20, 20, 512)  2359808     activation_55[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_54 (BatchNo (None, 20, 20, 512)  2048        conv2d_54[0][0]                  \n","__________________________________________________________________________________________________\n","activation_56 (Activation)      (None, 20, 20, 512)  0           batch_normalization_54[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_15 (MaxPooling2D) (None, 10, 10, 512)  0           activation_56[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_55 (Conv2D)              (None, 10, 10, 1024) 4719616     max_pooling2d_15[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_55 (BatchNo (None, 10, 10, 1024) 4096        conv2d_55[0][0]                  \n","__________________________________________________________________________________________________\n","activation_57 (Activation)      (None, 10, 10, 1024) 0           batch_normalization_55[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_56 (Conv2D)              (None, 10, 10, 1024) 9438208     activation_57[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_56 (BatchNo (None, 10, 10, 1024) 4096        conv2d_56[0][0]                  \n","__________________________________________________________________________________________________\n","activation_58 (Activation)      (None, 10, 10, 1024) 0           batch_normalization_56[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_11 (UpSampling2D) (None, 20, 20, 1024) 0           activation_58[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_11 (Concatenate)    (None, 20, 20, 1536) 0           up_sampling2d_11[0][0]           \n","                                                                 activation_56[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_57 (Conv2D)              (None, 20, 20, 512)  7078400     concatenate_11[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_57 (BatchNo (None, 20, 20, 512)  2048        conv2d_57[0][0]                  \n","__________________________________________________________________________________________________\n","activation_59 (Activation)      (None, 20, 20, 512)  0           batch_normalization_57[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_58 (Conv2D)              (None, 20, 20, 512)  2359808     activation_59[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_58 (BatchNo (None, 20, 20, 512)  2048        conv2d_58[0][0]                  \n","__________________________________________________________________________________________________\n","activation_60 (Activation)      (None, 20, 20, 512)  0           batch_normalization_58[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_12 (UpSampling2D) (None, 40, 40, 512)  0           activation_60[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_12 (Concatenate)    (None, 40, 40, 768)  0           up_sampling2d_12[0][0]           \n","                                                                 activation_54[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_59 (Conv2D)              (None, 40, 40, 256)  1769728     concatenate_12[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_59 (BatchNo (None, 40, 40, 256)  1024        conv2d_59[0][0]                  \n","__________________________________________________________________________________________________\n","activation_61 (Activation)      (None, 40, 40, 256)  0           batch_normalization_59[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_60 (Conv2D)              (None, 40, 40, 256)  590080      activation_61[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_60 (BatchNo (None, 40, 40, 256)  1024        conv2d_60[0][0]                  \n","__________________________________________________________________________________________________\n","activation_62 (Activation)      (None, 40, 40, 256)  0           batch_normalization_60[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_13 (UpSampling2D) (None, 80, 80, 256)  0           activation_62[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_13 (Concatenate)    (None, 80, 80, 384)  0           up_sampling2d_13[0][0]           \n","                                                                 activation_52[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_61 (Conv2D)              (None, 80, 80, 128)  442496      concatenate_13[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_61 (BatchNo (None, 80, 80, 128)  512         conv2d_61[0][0]                  \n","__________________________________________________________________________________________________\n","activation_63 (Activation)      (None, 80, 80, 128)  0           batch_normalization_61[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_62 (Conv2D)              (None, 80, 80, 128)  147584      activation_63[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_62 (BatchNo (None, 80, 80, 128)  512         conv2d_62[0][0]                  \n","__________________________________________________________________________________________________\n","activation_64 (Activation)      (None, 80, 80, 128)  0           batch_normalization_62[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_14 (UpSampling2D) (None, 160, 160, 128 0           activation_64[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_14 (Concatenate)    (None, 160, 160, 192 0           up_sampling2d_14[0][0]           \n","                                                                 activation_50[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_63 (Conv2D)              (None, 160, 160, 64) 110656      concatenate_14[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_63 (BatchNo (None, 160, 160, 64) 256         conv2d_63[0][0]                  \n","__________________________________________________________________________________________________\n","activation_65 (Activation)      (None, 160, 160, 64) 0           batch_normalization_63[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_64 (Conv2D)              (None, 160, 160, 64) 36928       activation_65[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_64 (BatchNo (None, 160, 160, 64) 256         conv2d_64[0][0]                  \n","__________________________________________________________________________________________________\n","activation_66 (Activation)      (None, 160, 160, 64) 0           batch_normalization_64[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_15 (UpSampling2D) (None, 320, 320, 64) 0           activation_66[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_15 (Concatenate)    (None, 320, 320, 96) 0           up_sampling2d_15[0][0]           \n","                                                                 activation_48[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_65 (Conv2D)              (None, 320, 320, 32) 27680       concatenate_15[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_65 (BatchNo (None, 320, 320, 32) 128         conv2d_65[0][0]                  \n","__________________________________________________________________________________________________\n","activation_67 (Activation)      (None, 320, 320, 32) 0           batch_normalization_65[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_66 (Conv2D)              (None, 320, 320, 32) 9248        activation_67[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_66 (BatchNo (None, 320, 320, 32) 128         conv2d_66[0][0]                  \n","__________________________________________________________________________________________________\n","activation_68 (Activation)      (None, 320, 320, 32) 0           batch_normalization_66[0][0]     \n","__________________________________________________________________________________________________\n","spatial_dropout2d_3 (SpatialDro (None, 320, 320, 32) 0           activation_68[0][0]              \n","__________________________________________________________________________________________________\n","final (Conv2D)                  (None, 320, 320, 41) 1353        spatial_dropout2d_3[0][0]        \n","__________________________________________________________________________________________________\n","activation_69 (Activation)      (None, 320, 320, 41) 0           final[0][0]                      \n","==================================================================================================\n","Total params: 31,468,073\n","Trainable params: 1,353\n","Non-trainable params: 31,466,720\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"F50lhrJfsE9V","colab_type":"text"},"source":["### Costruzione generatori di dataset"]},{"cell_type":"code","metadata":{"id":"8fDpbHNpkJ5o","colab_type":"code","colab":{}},"source":["TRAIN_BATCH_SIZE = 16\n","VAL_BATCH_SIZE = 1\n","LR = 0.0001\n","EPOCHS = 10\n","n_classes = 41"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Hky3fONufbf","colab_type":"code","outputId":"d8f51d3c-a077-4e65-91df-088a5fed41d3","executionInfo":{"status":"ok","timestamp":1590222815744,"user_tz":-120,"elapsed":1332,"user":{"displayName":"Andrea Scalvini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPXeWNqyQHU7lqzAh6lutN43ztPT6kRjC-mBXV=s64","userId":"07368200968117513143"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["# Dataset for train images\n","train_dataset = Dataset(\n","    x_train, \n","    y_train,\n","    mapping = map_indexes\n",")\n","\n","# Dataset for validation images\n","valid_dataset = Dataset(\n","    x_val, \n","    y_val,\n","    mapping = np.arange(x_val.shape[0])\n",")\n","\n","train_dataloader = Dataloder(train_dataset, TRAIN_BATCH_SIZE, shuffle=True)\n","valid_dataloader = Dataloder(valid_dataset, VAL_BATCH_SIZE, shuffle=False)\n","\n","# check shapes for errors\n","assert train_dataloader[0][0].shape == (TRAIN_BATCH_SIZE, 320, 320, 3)\n","assert train_dataloader[0][1].shape == (TRAIN_BATCH_SIZE, 320, 320, 41)\n","\n","# define callbacks for learning rate scheduling and best checkpoints saving\n","#callbacks = [\n","#    tf.keras.callbacks.ModelCheckpoint('./best_model_augm.h5', save_weights_only=True, save_best_only=True, mode='min'),\n","#    tf.keras.callbacks.ReduceLROnPlateau(),\n","#]\n","\n","patience = 5\n","\n","callbacks = [\n","  ReduceLROnPlateau(monitor='val_f1', factor=0.5, patience=patience, min_lr=1e-9, epsilon=0.00001, verbose=1, mode='max'),\n","  EarlyStopping(monitor='val_f1', patience=patience, verbose=1, mode=\"max\"),\n","  ModelCheckpoint('zf_unet_224_nrmest_w.h5', monitor='val_loss', save_best_only=True, verbose=0),\n","]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n","  warnings.warn('`epsilon` argument is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"2rdH0hR9sIHy","colab_type":"text"},"source":["### Fit del modello"]},{"cell_type":"code","metadata":{"id":"0pkZ5oBgrQm7","colab_type":"code","outputId":"9f91470a-00d1-4623-9b1e-9af9cd3d9fcd","executionInfo":{"status":"ok","timestamp":1590224752674,"user_tz":-120,"elapsed":1925779,"user":{"displayName":"Andrea Scalvini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPXeWNqyQHU7lqzAh6lutN43ztPT6kRjC-mBXV=s64","userId":"07368200968117513143"}},"colab":{"base_uri":"https://localhost:8080/","height":625}},"source":["# train model\n","history = model.fit(\n","    train_dataloader, \n","    steps_per_epoch=len(train_dataloader), \n","    epochs=EPOCHS*3, \n","    callbacks=callbacks, \n","    validation_data=valid_dataloader, \n","    validation_steps=len(valid_dataloader)\n",")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","303/303 [==============================] - 121s 400ms/step - loss: 5.2087 - dice_coef: 0.0394 - f1: 0.0068 - val_loss: 13.8720 - val_dice_coef: 0.0760 - val_f1: 0.0836\n","Epoch 2/30\n","303/303 [==============================] - 120s 398ms/step - loss: 4.9249 - dice_coef: 0.0524 - f1: 0.0074 - val_loss: 14.0900 - val_dice_coef: 0.0820 - val_f1: 0.0902\n","Epoch 3/30\n","303/303 [==============================] - 120s 398ms/step - loss: 4.8477 - dice_coef: 0.0583 - f1: 0.0055 - val_loss: 14.3832 - val_dice_coef: 0.0839 - val_f1: 0.0920\n","Epoch 4/30\n","303/303 [==============================] - 120s 397ms/step - loss: 4.8144 - dice_coef: 0.0618 - f1: 0.0052 - val_loss: 14.2939 - val_dice_coef: 0.0834 - val_f1: 0.0916\n","Epoch 5/30\n","303/303 [==============================] - 120s 397ms/step - loss: 4.7949 - dice_coef: 0.0633 - f1: 0.0047 - val_loss: 14.3158 - val_dice_coef: 0.0840 - val_f1: 0.0922\n","Epoch 6/30\n","303/303 [==============================] - 120s 396ms/step - loss: 4.7835 - dice_coef: 0.0645 - f1: 0.0050 - val_loss: 14.1926 - val_dice_coef: 0.0835 - val_f1: 0.0918\n","Epoch 7/30\n","303/303 [==============================] - 120s 397ms/step - loss: 4.7763 - dice_coef: 0.0649 - f1: 0.0047 - val_loss: 14.1106 - val_dice_coef: 0.0832 - val_f1: 0.0915\n","Epoch 8/30\n","303/303 [==============================] - 120s 397ms/step - loss: 4.7702 - dice_coef: 0.0647 - f1: 0.0044 - val_loss: 13.9722 - val_dice_coef: 0.0831 - val_f1: 0.0913\n","Epoch 9/30\n","303/303 [==============================] - 120s 397ms/step - loss: 4.7652 - dice_coef: 0.0654 - f1: 0.0045 - val_loss: 14.0406 - val_dice_coef: 0.0836 - val_f1: 0.0919\n","Epoch 10/30\n","303/303 [==============================] - 120s 395ms/step - loss: 4.7616 - dice_coef: 0.0654 - f1: 0.0043 - val_loss: 14.1132 - val_dice_coef: 0.0842 - val_f1: 0.0925\n","Epoch 11/30\n","303/303 [==============================] - 120s 396ms/step - loss: 4.7564 - dice_coef: 0.0657 - f1: 0.0041 - val_loss: 14.1980 - val_dice_coef: 0.0849 - val_f1: 0.0934\n","Epoch 12/30\n","303/303 [==============================] - 120s 395ms/step - loss: 4.7546 - dice_coef: 0.0655 - f1: 0.0045 - val_loss: 13.8612 - val_dice_coef: 0.0829 - val_f1: 0.0913\n","Epoch 13/30\n","303/303 [==============================] - 120s 396ms/step - loss: 4.7520 - dice_coef: 0.0659 - f1: 0.0043 - val_loss: 13.4454 - val_dice_coef: 0.0817 - val_f1: 0.0901\n","Epoch 14/30\n","303/303 [==============================] - 120s 396ms/step - loss: 4.7507 - dice_coef: 0.0656 - f1: 0.0037 - val_loss: 13.8006 - val_dice_coef: 0.0835 - val_f1: 0.0919\n","Epoch 15/30\n","303/303 [==============================] - 120s 396ms/step - loss: 4.7487 - dice_coef: 0.0658 - f1: 0.0036 - val_loss: 13.8270 - val_dice_coef: 0.0833 - val_f1: 0.0919\n","Epoch 16/30\n","303/303 [==============================] - 120s 395ms/step - loss: 4.7477 - dice_coef: 0.0658 - f1: 0.0038 - val_loss: 13.7738 - val_dice_coef: 0.0836 - val_f1: 0.0922\n","\n","Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","Epoch 00016: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gO9Sz7MFxKYc","colab_type":"code","colab":{}},"source":["indexes = x_train.shape[0]\n","indexes = np.arange(0,indexes,6)\n","x_train_ = x_train[indexes, ]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iRdIVrhPyGW-","colab_type":"code","colab":{}},"source":["y_train.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gwc1bAayxq2B","colab_type":"code","colab":{}},"source":["history = model.fit(\n","    x_train_,\n","    y_train, \n","    #steps_per_epoch=len(train_dataloader)/3, \n","    epochs=EPOCHS*3, \n","    callbacks=callbacks, \n","    #validation_data=[x_val, y_val]\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FCkHD593z_G5","colab_type":"code","colab":{}},"source":["# Plot training & validation iou_score values\n","plt.figure(figsize=(30, 5))\n","plt.subplot(121)\n","plt.plot(history.history['f1-score'])\n","plt.plot(history.history['val_f1-score'])\n","plt.title('Model f1 score')\n","plt.ylabel('f1-score')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","\n","# Plot training & validation loss values\n","plt.subplot(122)\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3fvE6z8W69T2","colab_type":"text"},"source":["## Calcolo output predizionale della rete"]},{"cell_type":"code","metadata":{"id":"thq_gXo1gDDX","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","model.load_weights(\"best_model.h5\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f4RJgsSxiUge","colab_type":"code","colab":{}},"source":["y_test_p = model.predict(x_test, batch_size=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p8LVIH1y7kTA","colab_type":"code","colab":{}},"source":["np.save(PATH_BASE + \"prediction_test_padded.npy\", y_test_p)"],"execution_count":0,"outputs":[]}]}